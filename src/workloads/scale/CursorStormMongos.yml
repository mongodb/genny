SchemaVersion: 2018-07-01
Owner: Service Architecture
Description: |
  Used to test performance of the router under heavy memory pressure caused by accumulating
  many heavy cursors. This workload is expected to fail due to host(s) being unreachable as a
  result of mongos running out of memory.

Keywords:
- scale
- memory stress
- cursor storm
- mongos
- oom
- out of memory

GlobalDefaults:
  dbname: &DBName memorystress
  MaxPhases: &MaxPhases 20

  LoadThreads: &LoadThreads 128
  LoadBatchSize: &LoadBatchSize 500

  NumberOfDocuments: &NumDocs 20096
  # NumberOfDocumentsPerWorker = NumberOfDocuments / LoadThreads.
  NumberOfDocumentsPerWorker: &DocsPerThread 157
  # Used in Document: a to let the starting value of a = 0.
  DocumentStartAt: &DocStartAt -157
  DocSize: &DocSize 168000
  Document: &Doc
    # Document number/ID. Starts at *DocStartAt = -*DocsPerThread = -157 because ActorId
    # starts at 1, and therefore in order for the first output of ^Inc to be 0, "start"
    # would need to be offset by ActorId * *DocsPerThread = 157.
    a: {^Inc: {start: *DocStartAt, step: 1, multiplier: *DocsPerThread}}
    # Random number from [0, NumberOfDocuments].
    b: {^RandomInt: {min: 0, max: *NumDocs}}
    # Fill 168 KB.
    c: {^FastRandomString: {length: *DocSize}}

  # When fetching data from shards, mongos holds a cursor using up to 16MB per shard.
  # Therefore, with data evenly distributed across shards, the size of all documents to fetch in a step 
  # should approach <num_of_shards> * 16MB. With 2 shards placed in the test topology,  
  # the number of documents to process by each thread is tuned so that *SortStep * *DocSize ~= 32 MB,
  SortStep: &SortStep 180
  SortBatchSize: &SortBatchSize 180
  SortThreads: &SortThreads 250
  SortRepeat: &SortRepeat 5

Clients:
  Default:
    QueryOptions:
      socketTimeoutMS: -1
      maxPoolSize: 500
    
Actors:
# Drop database to get rid of stale data. Useful when running locally multiple times.
- Name: Setup
  Type: RunCommand
  Threads: 1
  Phases:
    OnlyActiveInPhases:
      Active: [0]
      NopInPhasesUpTo: *MaxPhases
      PhaseConfig:
        Repeat: 1
        Database: *DBName
        Operations:
        - OperationName: RunCommand
          OperationCommand: {dropDatabase: 1}

# Create collection
- Name: Create
  Type: RunCommand
  Threads: 1
  Phases:
    OnlyActiveInPhases:
      Active: [1]
      NopInPhasesUpTo: *MaxPhases
      PhaseConfig:
        Repeat: 1
        Database: *DBName
        Operations:
        - OperationName: RunCommand
          OperationCommand:
            create: Collection0

# Enable sharding
- Name: ShardCollection
  Type: AdminCommand
  Threads: 1
  Phases:
    OnlyActiveInPhases:
      Active: [2]
      NopInPhasesUpTo: *MaxPhases
      PhaseConfig:
        Repeat: 1
        Database: admin
        OnlyRunInInstance: sharded
        Operations:
        - OperationMetricsName: EnableSharding
          OperationName: AdminCommand
          OperationCommand:
            enableSharding: *DBName
        - OperationMetricsName: ShardCollection
          OperationName: AdminCommand
          OperationCommand:
            shardCollection: memorystress.Collection0
            key: {a: hashed}

# Load 20,096 documents around 168KB as described by the structure in GlobalDefaults.
- Name: LoadDocuments
  Type: Loader
  Threads: *LoadThreads
  Phases:
    OnlyActiveInPhases:
      Active: [3]
      NopInPhasesUpTo: *MaxPhases
      PhaseConfig:
        CollectionCount: 1
        Database: *DBName
        Repeat: 1
        Document: *Doc
        MultipleThreadsPerCollection: true
        DocumentCount: *NumDocs
        BatchSize: *LoadBatchSize

# Spawn many threads to sort enough documents to test the routers capacity to handle memory pressure.
- Name: SortMany
  Type: RunCommand
  Threads: *SortThreads
  Phases:
    OnlyActiveInPhases:
      Active: [4]
      NopInPhasesUpTo: *MaxPhases
      PhaseConfig:
        Repeat: *SortRepeat
        Database: *DBName
        Operations:
        - OperationMetricsName: SortMany
          OperationName: RunCommand
          OperationCommand:
            # Loader default collection name.
            aggregate: Collection0
            pipeline:
              [{$match:
                {$expr:
                  {$let:
                    {vars:
                      {start: {^RandomInt: {min: 0, max: *NumDocs}}},
                    in: {$and: [$gte: ["$a", "$$start"], $lt: ["$a", {$add: ["$$start", *SortStep]}]]}
                    }
                  }
                }
              },
              # Blocking sort increases the number of heavy cursors kept in the system at once.
              {$sort: {b: 1}}]
            cursor: {batchSize: *SortBatchSize}

# Commented out because this should not be regularly scheduled, as the task is expected to fail.
# Uncomment the lines below (and possibly change the build variant) to run the workload.
# AutoRun:
# - When:
#     mongodb_setup:
#       $eq:
#       - shard-lite
