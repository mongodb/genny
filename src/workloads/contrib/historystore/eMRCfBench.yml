SchemaVersion: 2018-07-01
Owner: Storage Engines

# Test workload to evaluate Storage Engine behavior when running in a 
# degraded replica set with or without eMRCf enabled.  A "degraded" replica
# set here means one without an active majority of data bearing nodes.  I.e.,
# a PSA set with the Secondary offline.  

# Currently the workload is split across several yml files because we need to script
# some things between different parts.  This is the grow phase.  It churns our dataset
# with a lot of updates, inserts, and deletes.  It intent is to keep the logical size
# of the data set the same (i.e., same number of documents with the same large/small mix)
# but to cause the WT history store to grow when we run it on a degraded PSA replica set.

# This section contains shared definitions that are used in the workload.
# These defaults should match the similar declarations in the yml files for the other
# parts of the workload.
GlobalDefaults:
  Random10KInt: &rand_10k_int {^RandomInt: {min: 1, max: 10000}}
  Random1KInt: &rand_1k_int {^RandomInt: {min: 1, max: 1000}}
  Random4ByteInt: &rand_4b_int {^RandomInt: {min: 0, max: 2147483647}}
  ShortString: &short_string {^RandomString: {length: 16}}
  RandomShortString: &rand_short_string {^RandomString: {length: {^RandomInt: {min: 10, max: 160}}}}
  RandomMediumString: &rand_medium_string {^RandomString: {length: {^RandomInt: {min: 160, max: 960}}}}
  RandomLargeString: &rand_large_string {^RandomString: {length: {^RandomInt: {min: 960, max: 4960}}}}

  TestDB: &TestDB test # Name of test database

  SmallDocCount: &small_doc_count 10000000
  LargeDocCount: &large_doc_count 1000000

  # Documents have a key field.  Large and small documents use different, non-overlapping key
  # ranges so that we can choose one type of document or the other in later phases.
  # Key space for large and small docs should be 1% of the number of documents of each type.
  # This means that a updateOne request to a random key will select among 1% of the documents:
  # the oldest doc with each key value.
  SmallDocKey: &small_doc_key {^RandomInt: {min: 0, max: 100000}}
  LargeDocKey: &large_doc_key {^RandomInt: {min: 1000000, max: 1010000}}

# Each document has two keys.  A primary key (key1) is assigned randomly from the keyspace.
# The number of documents in the collection is 100x the range of the primary key.  So we will
# wind up with, on average, 100 documets per key value.  This is a hack so we can target tests
# at a set of "hot" documents.  Calling updateOne (or any of the other *One operations) with
# a random key will target the oldest document with that key value, thus 1% of the dataset
#
# The secondary key (key2) is a random value selected from 1 to 1000.  It can be used (awkwardly)
# to broaden the set of documents that a test targets.  For example, issuing a pair of operations 
# to random primary keys and one selecting key2 <= 500 and the other selecting key2 > 500 will
# target two documents for each primary key value, thus targeting 2 documents for each key
# value, or 2% of the population.

Document: &small_doc
  key1: *small_doc_key
  key2: *rand_1k_int
  data1: *rand_4b_int
  data2: *rand_4b_int
  data3: *rand_10k_int
  data4: *rand_1k_int
  type: "small"
  tag: *short_string
  payload: *rand_short_string

Document: &large_doc
  key1: *large_doc_key
  key2: *rand_1k_int
  data1: *rand_4b_int
  data2: *rand_4b_int
  data3: *rand_10k_int
  data4: *rand_1k_int
  type: "large"
  tag: *short_string
  payload: *rand_medium_string

# We're going to do a phased workload with some inspiration from YCSB
# 1. Inserts: Insert N documents
# 2. Update heavy:  50/50 reads/writes
# 3. Read mostly: 90/10 reads/writes
# 4. Deletes: Delete the N documents
#
# N is 1,000,000 --- 10 threads doing 100K ops each.
#
# In principle this could all be done from a single CrudActor instance.  But we put each phase
# in a different actor so we can give them different names to distinguish them in the metrics
# output csv.
Actors:
- Name: InsertPhase
  Type: CrudActor
  Database: *TestDB
  Threads: 10
  Phases: 
  - Repeat: 100000
    Threads: 10
    Collection: Collection0
    Operations:
    - OperationName: insertOne
      OperationCommand:
        Document: *small_doc
  - {Nop: true}
  - {Nop: true}
  - {Nop: true}

# 50/50 mix of reads and updates.  Target 2% of document population
- Name: UpdateHeavyPhase
  Type: CrudActor
  Database: *TestDB
  Threads: 10
  Phases:
  - {Nop: true}
  - Repeat: 25000
    Threads: 10
    Collection: Collection0
    Operations:
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 500}} ] }
    - OperationName: updateOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$lte: 500}} ] }
        Update: {$set: {data1: *rand_4b_int}}
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$lte: 500}} ] }
    - OperationName: updateOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 500}} ] }
        Update: {$set: {payload: *rand_short_string}}
  - {Nop: true}
  - {Nop: true}

# 90/10 mix of reads/updates.  
- Name: ReadMostlyPhase
  Type: CrudActor
  Database: *TestDB
  Threads: 10
  Phases:
  - {Nop: true}
  - {Nop: true}
  - Repeat: 10000
    Threads: 10
    Collection: Collection0
    Operations:
    # Updates target 1% of documents
    - OperationName: updateOne
      OperationCommand:
        Filter: {key1: *small_doc_key}
        Update: {$set: {payload: *rand_short_string}}
    # 4 of 9 reads target 1% of documents
    - OperationName: findOne
      OperationCommand:
        Filter: {key1: *small_doc_key}
    - OperationName: findOne
      OperationCommand:
        Filter: {key1: *small_doc_key}
    - OperationName: findOne
      OperationCommand:
        Filter: {key1: *small_doc_key}
    - OperationName: findOne
      OperationCommand:
        Filter: {key1: *small_doc_key}
    # 5 of 9 reads target 5% of documents, using secondary key pick different documents for
    # a given primary key
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 0}}, {key2: {$lte: 200}} ] }
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 200}}, {key2: {$lte: 400}} ] }
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 400}}, {key2: {$lte: 600}} ] }
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 600}}, {key2: {$lte: 800}} ] }
    - OperationName: findOne
      OperationCommand:
        Filter: {$and: [ {key1: *small_doc_key}, {key2: {$gt: 800}}, {key2: {$lte: 1000}} ] }
  - {Nop: true}

# Delete the same number of documents that we added, returning the database to the original 
# population (i.e., # of documents)
- Name: DeletePhase
  Type: CrudActor
  Database: *TestDB
  Threads: 10
  Phases:
  - {Nop: true}
  - {Nop: true}
  - {Nop: true}
  - Repeat: 100000
    Threads: 10
    Collection: Collection0
    Operations:
      - OperationName: deleteOne
        OperationCommand: 
          Filter: {key1: *small_doc_key}

# WARNING: Future versions of Genny won't support the cvs-ftdc metrics format.
Metrics:
  Format: csv-ftdc
  Path: build/genny-metrics
