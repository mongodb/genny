SchemaVersion: 2018-07-01
Owner: Storage Engines

# Test workload to evaluate Storage Engine behavior when running in a 
# degraded replica set with or without eMRCf enabled.  A "degraded" replica
# set here means one without an active majority of data bearing nodes.  I.e.,
# a PSA set with the Secondary offline.  

# Currently the workload is split across several yml files because we need to script
# some things between different parts.  This is the population phase.  It starts with
# an empty database and populates it with an initial set of documents.  We create a mix
# of small (50-200 byte) and large (200-1000 byte) documents in a 10:1 ratio.  

# This section contains shared definitions that are used in the workload.
# These defaults should match the similar declarations in the yml files for the other
# parts of the workload.
GlobalDefaults:
  Random10KInt: &rand_10k_int {^RandomInt: {min: 1, max: 10000}}
  Random1KInt: &rand_1k_int {^RandomInt: {min: 1, max: 1000}}
  Random4ByteInt: &rand_4b_int {^RandomInt: {min: 0, max: 2147483647}}
  ShortString: &short_string {^RandomString: {length: 16}}
  RandomShortString: &rand_short_string {^RandomString: {length: {^RandomInt: {min: 10, max: 160}}}}
  RandomMediumString: &rand_medium_string {^RandomString: {length: {^RandomInt: {min: 160, max: 960}}}}
  RandomLargeString: &rand_large_string {^RandomString: {length: {^RandomInt: {min: 960, max: 4960}}}}

  TestDB: &TestDB test # Name of test database

  SmallDocCount: &small_doc_count 10000000
  LargeDocCount: &large_doc_count 1000000

  # Documents have a key field.  Large and small documents use different, non-overlapping key
  # ranges so that we can choose one type of document or the other in later phases.
  # Key space for large and small docs should be 1% of the number of documents of each type.
  # This means that a updateOne request to a random key will select among 1% of the documents:
  # the oldest doc with each key value.
  SmallDocKey: &small_doc_key {^RandomInt: {min: 0, max: 100000}}
  LargeDocKey: &large_doc_key {^RandomInt: {min: 1000000, max: 1010000}}

# Each document has two keys.  A primary key (key1) is assigned randomly from the keyspace.
# The number of documents in the collection is 100x the range of the primary key.  So we will
# wind up with, on average, 100 documets per key value.  This is a hack so we can target tests
# at a set of "hot" documents.  Calling updateOne (or any of the other *One operations) with
# a random key will target the oldest document with that key value, thus 1% of the dataset
#
# The secondary key (key2) is a random value selected from 1 to 1000.  It can be used (awkwardly)
# to broaden the set of documents that a test targets.  For example, issuing a pair of operations 
# to random primary keys and one selecting key2 <= 500 and the other selecting key2 > 500 will
# target two documents for each primary key value, thus targeting 2 documents for each key
# value, or 2% of the population.

Document: &small_doc
  key1: *small_doc_key
  key2: *rand_1k_int
  data1: *rand_4b_int
  data2: *rand_4b_int
  data3: *rand_10k_int
  data4: *rand_1k_int
  type: "small"
  tag: *short_string
  payload: *rand_short_string

Document: &large_doc
  key1: *large_doc_key
  key2: *rand_1k_int
  data1: *rand_4b_int
  data2: *rand_4b_int
  data3: *rand_10k_int
  data4: *rand_1k_int
  type: "large"
  tag: *short_string
  payload: *rand_medium_string

Actors:

# Load small documents
- Name: SmallDocumentCreator
  Type: Loader
  Threads: 10
  Phases:
  - Repeat: 1
    Database: *TestDB
    CollectionCount: 1
    Threads: 10
    DocumentCount: *small_doc_count
    BatchSize: 1000
    Document: *small_doc
    Indexes:
    - keys: {key1: 1, key2: 1}
    - keys: {data1: 1}
    - keys: {tag: 1}

# Load large documents.  We use 1/10 as many threads in the hope that the rate
# of insertion will be roughly 1/10 of the small document insertation rate.
- Name: LargeDocumentCreator
  Type: Loader
  Threads: 1
  Phases:
  - Repeat: 1
    Database: *TestDB
    CollectionCount: 1
    Threads: 1
    DocumentCount: *large_doc_count
    BatchSize: 100
    Document: *large_doc

# WARNING: Future versions of Genny won't support the cvs-ftdc metrics format.
Metrics:
  Format: csv-ftdc
  Path: build/genny-metrics
