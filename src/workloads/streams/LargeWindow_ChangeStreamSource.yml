SchemaVersion: 2018-07-01
Owner: "@10gen/altas-streams"
Description: |
  Pipeline: Memory -> Tumbling Window (Group) -> Memory
  Documents: 16M
  BatchSize: 1k

  The tumbling window will group by the auction ID. The first 8M documents will all have unique
  auction IDs and will measure the performance of the scenario where every document results in
  inserting a new key into the window. The latter 8M documents will all have an existing auction ID
  and will measure the performance of the scenario where every document results in updating an
  existing key in the window.

Keywords:
- streams

GlobalDefaults:
  DatabaseName: &DatabaseName test
  StreamProcessorName: &StreamProcessorName sp

  # Genny workload client typically has 16 CPUs, so use 16 inserter threads each inserting
  # 500 batches of 1k documents, so a total of 8M documents, which will all have unique keys
  # for the window so this will generate 8M keys on the open window.
  NumThreads: &NumThreads 16
  NumBatch1000xPerThread: &NumBatch1000xPerThread 50
  InputCollectionName: &InputCollectionName input

  Channel: &Channel {^RandomInt: { min: 0, max: 10000 }}
  Url: &Url {^FormatString: { format: "https://www.nexmark.com/%s/%s/%s/item.htm?query=1&channel_id=%d", withArgs: [
    {^RandomString: { length: {^RandomInt: { min: 3, max: 5 }}}},
    {^RandomString: { length: {^RandomInt: { min: 3, max: 5 }}}},
    {^RandomString: { length: {^RandomInt: { min: 3, max: 5 }}}},
    *Channel
  ]}}

  DocumentWithUniqueKey: &DocumentWithUniqueKey
    auction: {^Inc: { start: 1000, multipler: 1 }}
    bidder: {^Inc: { start: 1000, multipler: 1 }}
    price: {^RandomDouble: {min: 100, max: 100000000}}
    channel: *Channel
    url: *Url
    dateTime: "2023-01-01T00:00:00.000"

  DocumentWithExistingKey: &DocumentWithExistingKey
    auction: {^RandomInt: { min: 1000, max: 8001000 }}
    bidder: {^Inc: { start: 1000, multipler: 1 }}
    price: {^RandomDouble: {min: 100, max: 100000000}}
    channel: *Channel
    url: *Url
    dateTime: "2023-01-01T00:00:00.000"

  Batch10x_UniqueKey: &Batch10x_UniqueKey [*DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey, *DocumentWithUniqueKey]
  Batch100x_UniqueKey: &Batch100x_UniqueKey {^FlattenOnce: [*Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey, *Batch10x_UniqueKey]}
  Batch1000x_UniqueKey: &Batch1000x_UniqueKey {^FlattenOnce: [*Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey, *Batch100x_UniqueKey]}

  Batch10x_ExistingKey: &Batch10x_ExistingKey [*DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey, *DocumentWithExistingKey]
  Batch100x_ExistingKey: &Batch100x_ExistingKey {^FlattenOnce: [*Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey, *Batch10x_ExistingKey]}
  Batch1000x_ExistingKey: &Batch1000x_ExistingKey {^FlattenOnce: [*Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey, *Batch100x_ExistingKey]}

Actors:
- Name: Setup
  Type: RunCommand
  ClientName: Stream
  Threads: 1
  Phases:
  - Phase: 0
    Repeat: 1
    Database: *DatabaseName
    Operations:
    - OperationMetricsName: CreateStreamProcessor
      OperationName: RunCommand
      OperationCommand:
        streams_startStreamProcessor: ""
        name: *StreamProcessorName
        pipeline: [
          {
            $source: {
              connectionName: "db",
              db: *DatabaseName,
              coll: *InputCollectionName,
              timeField: { $convert: { input: "$dateTime", to: "date" }},
              allowedLateness: { size: 1, unit: "second" },
            }
          },
          {
            $tumblingWindow: {
              interval: { size: 1, unit: "second" },
              pipeline: [
                { 
                  $group: {
                    _id: "$auction",
                    minPrice: { $min: "$price" },
                    maxPrice: { $max: "$price" },
                    sumPrice: { $sum: "$price" },
                    avgPrice: { $avg: "$price" }
                  }
                }
              ]
            }
          },
          { $emit: { connectionName: "__testMemory" } }
        ]
        connections: [
          { name: "__testMemory", type: "in_memory", options: {} }]
          { name: "db", type: "atlas", options: { uri: {^ClientURI: { Name: "Default" }} }}
        ]
  - Phase: 1..2
    Nop: true
  - Phase: 3
    Repeat: 1
    Database: *DatabaseName
    Operations:
    - OperationMetricsName: Stop
      OperationName: RunCommand
      OperationCommand:
        streams_stopStreamProcessor: ""
        name: *StreamProcessorName

- Name: Inserter
  Type: CrudActor
  ClientName: Default
  Database: *DatabaseName
  Threads: *NumThreads
  Phases:
  - Phase: 0
    Nop: true
  - Phase: 1
    Repeat: *NumBatch1000xPerThread
    Collection: input
    Operations:
    - OperationName: insertMany
      OperationCommand:
        Documents: *Batch1000x_UniqueKey
  - Phase: 2
    Repeat: *NumBatch1000xPerThread
    Collection: input
    Operations:
    - OperationName: insertMany
      OperationCommand:
        Documents: *Batch1000x_ExistingKey
  - Phase: 3
    Nop: true

- Name: Stats_UniqueKey
  Type: StreamStatsReporter
  ClientName: Stream
  Database: *DatabaseName
  Threads: 1
  Phases:
  - Phase: 0
    Nop: true
  - Phase: 1
    Repeat: 1
    StreamProcessorName: *StreamProcessorName
    ExpectedDocumentCount: 800000
  - Phase: 2..3
    Nop: true

- Name: Stats_ExistingKey
  Type: StreamStatsReporter
  ClientName: Stream
  Database: *DatabaseName
  Threads: 1
  Phases:
  - Phase: 0..1
    Nop: true
  - Phase: 2
    Repeat: 1
    StreamProcessorName: *StreamProcessorName
    ExpectedDocumentCount: 1600000
  - Phase: 3
    Nop: true

AutoRun:
- When:
    mongodb_setup:
      $eq:
      - standalone-streams
    branch_name:
      $gte: v7.2
